---
title: "Activity 9 - Bootstrapping"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(tidyverse)
library(tidymodels)
```

## Creating Data

## 1. Go back through the previous code and explain what each line is doing by providing a comment. You are provided with an example in the first line and places for the rest of that code “sentence”. Do this for all the previous code chunk.

```{r}
# Set a random seed value so we can obtain the same "random" results
  set.seed(2023)

  # Create a data frame/tibble named sim_dat
  sim_dat <- tibble(
  # Explain what next line is doing
    x1 = runif(20, -5, 5),
    
  #  The line `x1 = runif(20, -5, 5)` generates 20 random numbers uniformly distributed between -5 and 5 and assigns them to the `x1` column in the data frame `sim_dat`.
    
  # Explain what next line is doing
    x2 = runif(20, 0, 100),
  
# The line `x2 = runif(20, 0, 100)` generates 20 random numbers uniformly distributed between 0 and 100 and assigns them to the `x2` column in the data frame `sim_dat`.

  # Explain what next line is doing
    x3 = rbinom(20, 1, 0.5)

# The line `x3 = rbinom(20, 1, 0.5)` generates 20 random binary numbers (0 or 1) from a binomial distribution with a probability of 0.5  and assigns them to the column `x3` in the data frame `sim_dat`.
    )

  b0 <- 2
  b1 <- 0.25
  b2 <- -0.5
  b3 <- 1
  sigma <- 1.5

  errors <- rnorm(20, 0, sigma)

  sim_dat <- sim_dat %>% 
    mutate(
      y = b0 + b1*x1 + b2*x2 + b3*x3 + errors,
      x3 = case_when(
        x3 == 0 ~ "No",
        TRUE ~ "Yes"
        )
      )
```

### 2. What is the true (population-level) model? Note that we are adding noise/variability, but based on the above code you can see what the“baseline” model is.
    
    **Ignoring the errors term (which represents the random noise/variability), the true (population-level) model is: y=2+0.25⋅x1−0.5⋅x2+1⋅x3**

    Where:
      y is the dependent variable.
      x1 is a continuous independent variable uniformly distributed between -5 and       5.
      x2 is a continuous independent variable uniformly distributed between 0 and        100.
      x3 is a binary independent variable which is either 0 or 1 (later converted        to "No" or "Yes").

## Create graphical visualizations for the relationship between all variable *pair*s (i.e., `y` and each `x` and also each `x` pair). Provide a brief summary of what you see/notice. That is, how do these relationships compare with your comments from (1) and model in (2)? Especially for the relationship between `y` and each `x`. Hint: Do you remember what function/package makes this very easy to produce?

```{r}
library(GGally)
library(tidyverse)

# Simulate the data
set.seed(2023)
sim_dat <- tibble(
  x1 = runif(20, -5, 5),
  x2 = runif(20, 0, 100),
  x3 = rbinom(20, 1, 0.5)
)

b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5
errors <- rnorm(20, 0, sigma)

sim_dat <- sim_dat %>% 
  mutate(
    y = b0 + b1 * x1 + b2 * x2 + b3 * x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
    )
  )

# Create pairwise plots
ggpairs(sim_dat)

```

## Task 4: Traditional MLR model

```{r}
mlr_fit <- linear_reg() %>%
    set_mode("regression") %>% 
    set_engine("lm") %>% 
    fit(y ~ x1 + x2 + x3, data = sim_dat)

  # Also include the confidence intervals for our estimated slope parameters
  tidy(mlr_fit, conf.int = TRUE)
```

Answer the following question:

4.  Looking at your population-level model from (2), how accurate are
    your results? Explain how you made this decision. That is, what did
    you use from your output and how did you use that information to
    decide?
    
## Task 5: Bootstrapping

Create a new R code chunk and type the following code:

```{r}
# Set a random seed value so we can obtain the same "random" results
set.seed(631)

# Generate the 2000 bootstrap samples
boot_samps <- sim_dat %>% 
  bootstraps(times = 2000)

boot_samps
```
```{r}
# Create a function that fits a fixed MLR model to one split dataset
fit_mlr_boots <- function(split) {
  lm(y ~ x1 + x2 + x3, data = analysis(split))
}

# Fit the model to each split and store the information
# Also, obtain the tidy model information
boot_models <- boot_samps %>% 
  mutate(
    model = map(splits, fit_mlr_boots),
    coef_info = map(model, tidy)
    )

boots_coefs <- boot_models %>% 
  unnest(coef_info)

boots_coefs
```

```{r}
boot_int <- int_pctl(boot_models, statistics = coef_info, alpha = 0.05)
boot_int
```
```{r}
ggplot(boots_coefs, aes(x = estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(data = boot_int, aes(xintercept = .lower), col = "blue") +
  geom_vline(data = boot_int, aes(xintercept = .upper), col = "blue")
```






